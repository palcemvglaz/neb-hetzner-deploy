#!/usr/bin/env python3
"""
YouTube Comments Collector using YouTube Data API
–ü–æ—Ç—Ä–µ–±—É—î YouTube API key –≤ –∑–º—ñ–Ω–Ω—ñ–π —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ YOUTUBE_API_KEY
"""

import os
import json
from datetime import datetime
from typing import List, Dict, Optional
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

class YouTubeAPICollector:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('YOUTUBE_API_KEY')
        if not self.api_key:
            raise ValueError("YouTube API key –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å YOUTUBE_API_KEY")
        
        self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        self.comments_data = []
        self.playlist_id = "PLNz8wZnk2_6WvkuOVxq-wubNOPGHYTfk3"
    
    def get_playlist_videos(self) -> List[Dict]:
        """–û—Ç—Ä–∏–º—É—î –≤—Å—ñ –≤—ñ–¥–µ–æ –∑ –ø–ª–µ–π–ª–∏—Å—Ç–∞"""
        videos = []
        next_page_token = None
        
        try:
            while True:
                playlist_response = self.youtube.playlistItems().list(
                    part='snippet',
                    playlistId=self.playlist_id,
                    maxResults=50,
                    pageToken=next_page_token
                ).execute()
                
                for item in playlist_response.get('items', []):
                    video_info = {
                        'video_id': item['snippet']['resourceId']['videoId'],
                        'title': item['snippet']['title'],
                        'published_at': item['snippet']['publishedAt']
                    }
                    videos.append(video_info)
                
                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break
                    
        except HttpError as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ API: {e}")
            
        return videos
    
    def get_video_comments(self, video_id: str, video_title: str) -> List[Dict]:
        """–û—Ç—Ä–∏–º—É—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤—ñ–¥–µ–æ"""
        comments = []
        next_page_token = None
        
        try:
            while len(comments) < 100:  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 100 –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –Ω–∞ –≤—ñ–¥–µ–æ
                comments_response = self.youtube.commentThreads().list(
                    part='snippet',
                    videoId=video_id,
                    maxResults=100,
                    pageToken=next_page_token,
                    order='relevance'  # –ù–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
                ).execute()
                
                for item in comments_response.get('items', []):
                    comment_data = item['snippet']['topLevelComment']['snippet']
                    
                    comment = {
                        'author': comment_data['authorDisplayName'],
                        'author_channel_url': comment_data['authorChannelUrl'],
                        'text': comment_data['textDisplay'],
                        'published_at': comment_data['publishedAt'],
                        'updated_at': comment_data.get('updatedAt', comment_data['publishedAt']),
                        'like_count': comment_data['likeCount'],
                        'video_id': video_id,
                        'video_title': video_title,
                        'video_url': f"https://www.youtube.com/watch?v={video_id}"
                    }
                    
                    comments.append(comment)
                
                next_page_token = comments_response.get('nextPageToken')
                if not next_page_token:
                    break
                    
        except HttpError as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –≤—ñ–¥–µ–æ {video_id}: {e}")
            
        return comments
    
    def classify_comment_for_marketing(self, comment: Dict) -> Dict:
        """–ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î –∫–æ–º–µ–Ω—Ç–∞—Ä –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–∏—Ö —Ü—ñ–ª–µ–π"""
        text = comment['text'].lower()
        
        # –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        categories = {
            'testimonial': {
                'keywords': ['–∑–∞–≤–¥—è–∫–∏', '–±–ª–∞–≥–æ–¥–∞—Ä—è', 'thanks to', '–¥–æ–ø–æ–º–æ–≥–ª–æ', 'helped', 
                           '–≤—Ä—è—Ç—É–≤–∞–ª–æ', 'saved', '–Ω–∞–≤—á–∏–≤—Å—è', 'learned', '—Ç–µ–ø–µ—Ä —è', 'now i'],
                'weight': 5
            },
            'positive_feedback': {
                'keywords': ['—á—É–¥–æ–≤–æ', 'excellent', '–Ω–∞–π–∫—Ä–∞—â', 'best', '—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', 
                           'recommend', '–∫–æ—Ä–∏—Å–Ω–æ', 'useful', '–¥—è–∫—É—é', 'thanks'],
                'weight': 3
            },
            'success_story': {
                'keywords': ['–≤–¥–∞–ª–æ—Å—è', 'managed', '–∑–º—ñ–≥', '–¥–æ—Å—è–≥', 'achieved', 
                           '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', 'result', '–ø–æ–∫—Ä–∞—â', 'improved'],
                'weight': 4
            },
            'emotional': {
                'keywords': ['‚ù§Ô∏è', 'üî•', 'üí™', 'üèçÔ∏è', '–ª—é–±–ª—é', 'love', '–∑–∞—Ö–≤–∞—Ç', 'amazing'],
                'weight': 2
            },
            'specific_benefit': {
                'keywords': ['–±–µ–∑–ø–µ–∫–∞', 'safety', '–≤–ø–µ–≤–Ω–µ–Ω', 'confident', '–ø—Ä–æ—Ñ–µ—Å—ñ–æ–Ω–∞–ª', 
                           'professional', '–¥–æ—Å–≤—ñ–¥', 'experience'],
                'weight': 4
            }
        }
        
        score = 0
        matched_categories = []
        
        # –ë–∞–∑–æ–≤—ñ –±–∞–ª–∏ –∑–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        if len(text) > 100:
            score += 2
        if comment['like_count'] > 5:
            score += 2
        if comment['like_count'] > 20:
            score += 3
            
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
        for category, data in categories.items():
            for keyword in data['keywords']:
                if keyword in text:
                    score += data['weight']
                    matched_categories.append(category)
                    break
        
        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä—ñ–≤–Ω—è —è–∫–æ—Å—Ç—ñ
        if score >= 10:
            quality_level = 'excellent'
        elif score >= 6:
            quality_level = 'good'
        elif score >= 3:
            quality_level = 'moderate'
        else:
            quality_level = 'low'
            
        return {
            'score': score,
            'quality_level': quality_level,
            'categories': list(set(matched_categories)),
            'is_marketing_worthy': score >= 6
        }
    
    def collect_all_comments(self):
        """–ó–±–∏—Ä–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –∑ —É—Å—ñ—Ö –≤—ñ–¥–µ–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞"""
        print(f"üîç –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–µ–æ –∑ –ø–ª–µ–π–ª–∏—Å—Ç–∞ {self.playlist_id}...")
        videos = self.get_playlist_videos()
        print(f"üìπ –ó–Ω–∞–π–¥–µ–Ω–æ {len(videos)} –≤—ñ–¥–µ–æ")
        
        for i, video in enumerate(videos, 1):
            print(f"\nüì∫ –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ {i}/{len(videos)}: {video['title']}")
            
            comments = self.get_video_comments(video['video_id'], video['title'])
            print(f"   üí¨ –ó–Ω–∞–π–¥–µ–Ω–æ {len(comments)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
            
            # –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î–º–æ –∫–æ–∂–µ–Ω –∫–æ–º–µ–Ω—Ç–∞—Ä
            for comment in comments:
                classification = self.classify_comment_for_marketing(comment)
                comment['marketing_classification'] = classification
                
                # –î–æ–¥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —è–∫—ñ—Å–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ
                if classification['is_marketing_worthy']:
                    self.comments_data.append(comment)
            
            print(f"   ‚ú® –í—ñ–¥—ñ–±—Ä–∞–Ω–æ {sum(1 for c in comments if c['marketing_classification']['is_marketing_worthy'])} —è–∫—ñ—Å–Ω–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    def save_results(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏"""
        output_dir = "/Users/chyngys/scripts/neb-content-appv2/marketing_data"
        os.makedirs(output_dir, exist_ok=True)
        
        # –û—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª –∑ —É—Å—ñ–º–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—è–º–∏
        all_comments_file = os.path.join(output_dir, "youtube_comments_all.json")
        with open(all_comments_file, 'w', encoding='utf-8') as f:
            json.dump({
                'collection_date': datetime.now().isoformat(),
                'playlist_id': self.playlist_id,
                'total_comments': len(self.comments_data),
                'comments': self.comments_data
            }, f, ensure_ascii=False, indent=2)
        
        # –§–∞–π–ª –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä—è–º–∏ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É
        excellent_comments = [c for c in self.comments_data 
                            if c['marketing_classification']['quality_level'] == 'excellent']
        
        best_comments_file = os.path.join(output_dir, "youtube_comments_best.json")
        with open(best_comments_file, 'w', encoding='utf-8') as f:
            json.dump({
                'collection_date': datetime.now().isoformat(),
                'total_excellent': len(excellent_comments),
                'comments': excellent_comments
            }, f, ensure_ascii=False, indent=2)
        
        # –§–∞–π–ª –∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—è–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö
        categorized_file = os.path.join(output_dir, "youtube_comments_by_category.json")
        categories_dict = {}
        
        for comment in self.comments_data:
            for category in comment['marketing_classification']['categories']:
                if category not in categories_dict:
                    categories_dict[category] = []
                categories_dict[category].append({
                    'author': comment['author'],
                    'text': comment['text'],
                    'video_title': comment['video_title'],
                    'date': comment['published_at'],
                    'likes': comment['like_count'],
                    'url': comment['video_url']
                })
        
        with open(categorized_file, 'w', encoding='utf-8') as f:
            json.dump(categories_dict, f, ensure_ascii=False, indent=2)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ Markdown —Ñ–∞–π–ª –¥–ª—è –ª–µ–≥–∫–æ–≥–æ –ø–µ—Ä–µ–≥–ª—è–¥—É
        markdown_file = os.path.join(output_dir, "youtube_comments_for_marketing.md")
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write("# YouTube Comments for Marketing\n\n")
            f.write(f"Collected on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            
            f.write("## üåü Excellent Testimonials\n\n")
            for comment in excellent_comments[:10]:  # Top 10
                f.write(f"### {comment['author']}\n")
                f.write(f"*Video: {comment['video_title']}*\n")
                f.write(f"*Date: {comment['published_at'][:10]}*\n")
                f.write(f"*Likes: {comment['like_count']}*\n\n")
                f.write(f"> {comment['text']}\n\n")
                f.write("---\n\n")
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ:")
        print(f"   üìÑ –í—Å—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ: {all_comments_file}")
        print(f"   ‚≠ê –ù–∞–π–∫—Ä–∞—â—ñ: {best_comments_file}")
        print(f"   üìä –ü–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö: {categorized_file}")
        print(f"   üìù Markdown: {markdown_file}")

def main():
    try:
        # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ API
        collector = YouTubeAPICollector()
        collector.collect_all_comments()
        collector.save_results()
        
        print(f"\nüìä –§—ñ–Ω–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å—å–æ–≥–æ —è–∫—ñ—Å–Ω–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤: {len(collector.comments_data)}")
        
        excellent = sum(1 for c in collector.comments_data 
                       if c['marketing_classification']['quality_level'] == 'excellent')
        good = sum(1 for c in collector.comments_data 
                  if c['marketing_classification']['quality_level'] == 'good')
        
        print(f"   –í—ñ–¥–º—ñ–Ω–Ω–∏—Ö: {excellent}")
        print(f"   –•–æ—Ä–æ—à–∏—Ö: {good}")
        
    except ValueError as e:
        print(f"\n‚ö†Ô∏è  {e}")
        print("\nüìù –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –ø–æ –æ—Ç—Ä–∏–º–∞–Ω–Ω—é YouTube API Key:")
        print("1. –ü–µ—Ä–µ–π–¥—ñ—Ç—å –Ω–∞ https://console.cloud.google.com/")
        print("2. –°—Ç–≤–æ—Ä—ñ—Ç—å –Ω–æ–≤–∏–π –ø—Ä–æ–µ–∫—Ç –∞–±–æ –≤–∏–±–µ—Ä—ñ—Ç—å —ñ—Å–Ω—É—é—á–∏–π")
        print("3. –í–∫–ª—é—á—ñ—Ç—å YouTube Data API v3")
        print("4. –°—Ç–≤–æ—Ä—ñ—Ç—å API key –≤ —Ä–æ–∑–¥—ñ–ª—ñ Credentials")
        print("5. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –∑–º—ñ–Ω–Ω—É —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞:")
        print("   export YOUTUBE_API_KEY='–≤–∞—à_–∫–ª—é—á_—Ç—É—Ç'")
        print("\n–ê–±–æ –∑–∞–ø—É—Å—Ç—ñ—Ç—å –ø—Ä–æ—Å—Ç–∏–π –∑–±–∏—Ä–∞—á –±–µ–∑ API:")
        print("   python scripts/youtube-comments-collector.py")

if __name__ == "__main__":
    main()